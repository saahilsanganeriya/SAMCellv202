{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd98975f8d86251e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T06:53:37.693107Z",
     "start_time": "2025-01-30T06:53:34.353028Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workbench/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/workbench/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/workbench/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "from SAMDataset import SAMDataset  # adjust path\n",
    "from utils import lr_warmup, init_wandb  # if you used that function\n",
    "from transformers import SamProcessor\n",
    "from model import FinetunedSAM\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T06:53:37.728835Z",
     "start_time": "2025-01-30T06:53:37.726478Z"
    }
   },
   "outputs": [],
   "source": [
    "def seg_loss_fn(lbl, pred, device):\n",
    "    \"\"\"\n",
    "    Suppose `lbl` shape => (B, 3, H, W), order = (dx, dy, cell_prob).\n",
    "    Suppose `pred` shape => (B, 3, H, W), same order.\n",
    "\n",
    "    We do MSE for (dx, dy) and BCE for cell_prob (the 3rd channel).\n",
    "    \"\"\"\n",
    "    # 1) parse out\n",
    "    dx_gt = lbl[:, 0]  # shape (B,H,W)\n",
    "    dy_gt = lbl[:, 1]\n",
    "    cp_gt = lbl[:, 2]  # cellprob => in [0,1] ?\n",
    "\n",
    "    dx_pred = pred[:, 0]\n",
    "    dy_pred = pred[:, 1]\n",
    "    cp_pred = sigmoid(pred[:, 2])\n",
    "\n",
    "    # 2) define losses\n",
    "    criterion_mse = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    # MSE on flows\n",
    "    flows_loss = criterion_mse(dx_pred, 5 * dx_gt) + criterion_mse(dy_pred, 5 * dy_gt)\n",
    "    # BCE on cellprob\n",
    "    cp_loss = criterion_mse(cp_pred, cp_gt)\n",
    "\n",
    "    total_loss = flows_loss + cp_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f856110fa1949846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T06:53:38.746100Z",
     "start_time": "2025-01-30T06:53:37.730895Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workbench/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with length: 540\n"
     ]
    }
   ],
   "source": [
    "# 1) Hyperparams\n",
    "sam_model_path = 'facebook/sam-vit-base'  # your local path\n",
    "dataset_path = '/project/data/CellPose-train/'\n",
    "img_path = dataset_path + \"imgs.npy\"\n",
    "ann_path = dataset_path + \"anns.npy\"\n",
    "flows_path = dataset_path + \"flows.npy\"  # shape => (N,3,H,W)\n",
    "weight_path = None  # or your path\n",
    "output_path = \"project/models/samcell_3ch/checkpoints\"\n",
    "num_epochs = 40\n",
    "batch_size = 2\n",
    "lr = 1e-4\n",
    "do_log_wandb = False\n",
    "\n",
    "# 2) Build the dataset\n",
    "# e.g. your custom dataset that returns:\n",
    "#   batch[\"pixel_values\"] => shape [B,3,H_in,W_in] (the input image)\n",
    "#   batch[\"ground_truth_mask\"] => shape [B,3,H_out,W_out] (the flowsX, flowsY, cellprob)\n",
    "\n",
    "\n",
    "# For example:\n",
    "#   processor = ...\n",
    "#   dataset = SAMDataset(img_path, ann_path, processor=processor)\n",
    "#   # but in your new pipeline, you might not do the huggingface SamProcessor if you are using SAM2 code?\n",
    "\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")  # or some SAM\n",
    "# (the transforms are used by your dataset's _preprocess & self.processor calls)\n",
    "dataset = SAMDataset(\n",
    "    img_path=img_path,\n",
    "    flow_path=flows_path,\n",
    "    ann_path=ann_path,\n",
    "    processor=processor,\n",
    "    weight_path=weight_path,\n",
    "    crop_size=256\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "print(\"Loaded dataset with length:\", len(dataset))\n",
    "\n",
    "# 3) Build the model\n",
    "modelHelper = FinetunedSAM(\n",
    "    sam_model=sam_model_path,\n",
    "    finetune_vision=False,\n",
    "    finetune_prompt=True,\n",
    "    finetune_decoder=True\n",
    ")\n",
    "model = modelHelper.get_model()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# 4) Build optimizer, etc.\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=0.1, betas=(0.9, 0.999))\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_warmup)  # if you want your custom schedule\n",
    "\n",
    "if do_log_wandb:\n",
    "    run = init_wandb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2262a97ae9e9d18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T06:55:35.178354Z",
     "start_time": "2025-01-30T06:53:38.754309Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/270 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_losses = []\n",
    "    for batch_data in tqdm(dataloader):\n",
    "        # batch_data:\n",
    "        #   batch_data[\"pixel_values\"] => shape [B,3,H_in,W_in]\n",
    "        #   batch_data[\"ground_truth_mask\"] => shape [B,3,H_out,W_out]\n",
    "        pixel_values = batch_data[\"pixel_values\"].to(device)\n",
    "\n",
    "        # forward pass => your SAM2 3Ch\n",
    "        # The model forward may differ depending on how your code is set up.\n",
    "        # Possibly something like:\n",
    "        outputs = model(pixel_values=pixel_values,\n",
    "                  multimask_output=True)\n",
    "        # outputs => structure with pred_masks => shape [B, 3, H_out, W_out], presumably\n",
    "\n",
    "        predicted_flows = outputs.pred_masks.squeeze(1)  # shape => [B, 3, H_out, W_out]\n",
    "        ground_truth_flows = batch_data[\"ground_truth_mask\"].float().to(device)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(\"ground_truth_flows.shape:\", ground_truth_flows.shape)\n",
    "\n",
    "            # --- Visualize the Flows and Distance Transform ---\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "            # Flow DY\n",
    "            im1 = axs[0].imshow(ground_truth_flows[0,1], cmap='jet')\n",
    "            axs[0].set_title(f\"Flow DY\")\n",
    "            plt.colorbar(im1, ax=axs[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "            # Flow DX\n",
    "            im2 = axs[1].imshow(ground_truth_flows[0,0], cmap='jet')\n",
    "            axs[1].set_title(f\"Flow DX\")\n",
    "            plt.colorbar(im2, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "            # Distance Transform (cell_prob)\n",
    "            im3 = axs[2].imshow(ground_truth_flows[0,2], cmap='jet')\n",
    "            axs[2].set_title(f\"Distance Transform (cell_prob)\")\n",
    "            plt.colorbar(im3, ax=axs[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            print(\"predicted_flows.shape:\", predicted_flows.shape)\n",
    "\n",
    "            # --- Visualize the Flows and Distance Transform ---\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "            # Flow DY\n",
    "            im1 = axs[0].imshow(predicted_flows[0,1].detach().cpu().numpy(), cmap='jet')\n",
    "            axs[0].set_title(f\"Flow DY\")\n",
    "            plt.colorbar(im1, ax=axs[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "            # Flow DX\n",
    "            im2 = axs[1].imshow(predicted_flows[0,0].detach().cpu().numpy(), cmap='jet')\n",
    "            axs[1].set_title(f\"Flow DX\")\n",
    "            plt.colorbar(im2, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "            # Distance Transform (cell_prob)\n",
    "            im3 = axs[2].imshow(predicted_flows[0,2].detach().cpu().numpy(), cmap='jet')\n",
    "            axs[2].set_title(f\"Distance Transform (cell_prob)\")\n",
    "            plt.colorbar(im3, ax=axs[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        # compute loss\n",
    "        loss_val = seg_loss_fn(ground_truth_flows, predicted_flows, device=device)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_losses.append(loss_val.item())\n",
    "        step += 1\n",
    "\n",
    "    print(f\"[Epoch {epoch}] Loss = {np.mean(epoch_losses):.4f}\")\n",
    "\n",
    "# 6) Save\n",
    "print(\"Saving fine-tuned weights to\", output_path)\n",
    "torch.save(model.state_dict(), output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c0b163d41d6eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
